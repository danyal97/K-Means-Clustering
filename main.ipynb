{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randint\n",
    "from nltk.stem import PorterStemmer\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords=open(\"Stopword-List.txt\")\n",
    "StopWords=StopWords.readlines()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTokensBySpace(File):\n",
    "    Tokens=[]\n",
    "    for Word in File:\n",
    "        Token=\"\"\n",
    "        for Character in Word:\n",
    "            if Character!=\" \":\n",
    "                Token+=Character\n",
    "            else:\n",
    "                Tokens.append(Token)\n",
    "                Token=\"\"\n",
    "    return Tokens\n",
    "def RemovingDots(Tokens):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        if Token.count(\".\")>=2: #For Initials like U.S.A\n",
    "            Result.append(Token.replace(\".\",\"\"))\n",
    "        else:\n",
    "            SplitByDot=re.split(\"\\.\",Token) # For Words Like Thousands.So\n",
    "            for Word in SplitByDot:\n",
    "                if Word!=\"\":\n",
    "                    Result.append(Word)\n",
    "    return Result\n",
    "\n",
    "def RemovingContractions(Tokens):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        Word=Token.replace(\"?\",\"\").replace(\":\",\"\").replace(\",\",\"\").replace('\"',\"\")\n",
    "        Word=re.split(r\"n't\",Word)\n",
    "        if len(Word)>1:\n",
    "            Word[1]=\"not\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'s\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"is\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'re\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"are\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'m\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"am\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'ll\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"will\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'ve\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"have\"\n",
    "        if len(Word)<2:\n",
    "            Word=re.split(r\"'d\",Word[0])\n",
    "            if len(Word)>1:\n",
    "                Word[1]=\"had\"\n",
    "        for W in Word:\n",
    "            if W!=\"\":\n",
    "                Result.append(W)\n",
    "    return Result\n",
    "\n",
    "def LOWERCASECONVERTOR(Tokens):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        Result.append(Token.lower())\n",
    "    return Result\n",
    "\n",
    "def RemovingBraces(Tokens): #[]\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        Words=re.split(r\"\\[(\\w+)\\]\",Token)\n",
    "        for Word in Words:\n",
    "            if Word!=\"\":\n",
    "                Result.append(Word)\n",
    "    return Result\n",
    "\n",
    "def RemovingHypens(Tokens):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        Words=re.split(r\"\\-\",Token)\n",
    "        for Word in Words:\n",
    "            if Word!=\"\":\n",
    "                Result.append(Word)\n",
    "    return Result\n",
    "\n",
    "def PorterStemming(Tokens):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        Result.append(ps.stem(Token))\n",
    "    return Result\n",
    "\n",
    "def GeneratingStopWordsList(File):\n",
    "    StopWordList=[]\n",
    "    for word in StopWords:\n",
    "        word=re.split(\"\\\\n\",word)\n",
    "        if word[0]!=\"\":\n",
    "            StopWordList.append(word[0].replace(\" \",\"\"))\n",
    "    return StopWordList\n",
    "\n",
    "\n",
    "def RemovingStopWords(Tokens,StopWordList):\n",
    "    Result=[]\n",
    "    for Token in Tokens:\n",
    "        if Token not in StopWordList:\n",
    "            Result.append(Token)\n",
    "    return Result\n",
    "\n",
    "def FinalFilter(SortedKeys):\n",
    "    \n",
    "    NewKeys=[]\n",
    "    \n",
    "    for i in SortedKeys:\n",
    "        i=i.replace(\"'\",\"\").replace(\";\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"Ã¢Â\",\"\").replace(\"Ã¢Â\",\"\")\n",
    "        NewKeys.append(i)\n",
    "    while \"\" in NewKeys:\n",
    "        NewKeys.remove(\"\")\n",
    "        \n",
    "    return NewKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Dictionary Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePostingList(directory):\n",
    "    \n",
    "    Dictionary={}\n",
    "    \n",
    "    IndexOfFile=0\n",
    "\n",
    "    Folders=next(os.walk(directory))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk(directory+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "        \n",
    "            File=open(directory+Folder+'/'+FileName)\n",
    "        \n",
    "            Speech=File.readlines()\n",
    "        \n",
    "            # Filtering Data\n",
    "        \n",
    "            StopWordList=GeneratingStopWordsList(StopWords)\n",
    "        \n",
    "            Tokens=GenerateTokensBySpace(Speech)\n",
    "        \n",
    "            Tokens=RemovingContractions(Tokens)\n",
    "        \n",
    "            Tokens=RemovingDots(Tokens)\n",
    "        \n",
    "            Tokens=LOWERCASECONVERTOR(Tokens)\n",
    "        \n",
    "            Tokens=RemovingBraces(Tokens)\n",
    "        \n",
    "            Tokens=RemovingHypens(Tokens)\n",
    "        \n",
    "            Tokens=FinalFilter(Tokens)\n",
    "        \n",
    "            Tokens=RemovingStopWords(Tokens,StopWordList)\n",
    "        \n",
    "            Tokens=PorterStemming(Tokens)\n",
    "        \n",
    "        \n",
    "            for i in range(0,len(Tokens)):\n",
    "                \n",
    "                Dictionary.setdefault(Tokens[i],{})\n",
    "        \n",
    "            IndexOfFile+=1\n",
    "        \n",
    "    return Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary=GeneratePostingList('Train/bbcsport/')\n",
    "SortedKeys=sorted(Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data set Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTotalDocuments(directory):\n",
    "    TotalTrainDoc=0\n",
    "    \n",
    "    Folders=next(os.walk(directory))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk(directory+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "            \n",
    "            TotalTrainDoc+=1\n",
    "    \n",
    "    return TotalTrainDoc\n",
    "\n",
    "def GetTotalFolder(directory):\n",
    "    \n",
    "    return len(next(os.walk(directory))[1])\n",
    "  \n",
    "def GetTotalFilesInClass(ClassName,directory):\n",
    "    \n",
    "    Files=next(os.walk(directory+ClassName))[2]\n",
    "    \n",
    "    return len(Files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Train Data Set Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Total Train Folders          :  5\n",
      "Total Train Documents        :  517\n",
      "Documents In Athletics Class :  71\n",
      "Documents In Cricket Class   :  87\n",
      "Documents In Football Class  :  186\n",
      "Documents In Rugby Class     :  103\n",
      "Documents In Tennis Class    :  70\n",
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*124)\n",
    "print(\"Total Train Folders          : \",GetTotalFolder('Train/bbcsport/'))\n",
    "print(\"Total Train Documents        : \",GetTotalDocuments('Train/bbcsport/'))\n",
    "print(\"Documents In Athletics Class : \",GetTotalFilesInClass('athletics','Train/bbcsport/'))\n",
    "print(\"Documents In Cricket Class   : \",GetTotalFilesInClass('cricket','Train/bbcsport/'))\n",
    "print(\"Documents In Football Class  : \",GetTotalFilesInClass('football','Train/bbcsport/'))\n",
    "print(\"Documents In Rugby Class     : \",GetTotalFilesInClass('rugby','Train/bbcsport/'))\n",
    "print(\"Documents In Tennis Class    : \",GetTotalFilesInClass('tennis','Train/bbcsport/'))\n",
    "print(\"*\"*124)\n",
    "TotalTrainDocuments=GetTotalDocuments('Train/bbcsport/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Train Data Set Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratingTrainCsvFile(Dictionary):\n",
    "    \n",
    "    SortedKeys=sorted(Dictionary) \n",
    "    \n",
    "    MatrixForTrainDataset=[[0 for i in range(0,len(SortedKeys)+1)]for j in range(0,TotalTrainDocuments)]\n",
    "\n",
    "    TermIdfMatrix=[[0 for i in range(0,len(SortedKeys)+1)]for j in range(0,TotalTrainDocuments)]\n",
    "    \n",
    "    IndexOfFile=0\n",
    "\n",
    "    Folders=next(os.walk('Train/bbcsport/'))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk('Train/bbcsport/'+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "        \n",
    "            File=open(\"Train/bbcsport/\"+Folder+'/'+FileName)\n",
    "        \n",
    "            Speech=File.readlines()\n",
    "        \n",
    "            # Filtering Data\n",
    "        \n",
    "            StopWordList=GeneratingStopWordsList(StopWords)\n",
    "        \n",
    "            Tokens=GenerateTokensBySpace(Speech)\n",
    "        \n",
    "            Tokens=RemovingContractions(Tokens)\n",
    "        \n",
    "            Tokens=RemovingDots(Tokens)\n",
    "        \n",
    "            Tokens=LOWERCASECONVERTOR(Tokens)\n",
    "        \n",
    "            Tokens=RemovingBraces(Tokens)\n",
    "        \n",
    "            Tokens=RemovingHypens(Tokens)\n",
    "            \n",
    "            Tokens=FinalFilter(Tokens)\n",
    "        \n",
    "            Tokens=RemovingStopWords(Tokens,StopWordList)\n",
    "        \n",
    "            Tokens=PorterStemming(Tokens)\n",
    "        \n",
    "        \n",
    "            for i in range(0,len(Tokens)):\n",
    "            \n",
    "                MatrixForTrainDataset[IndexOfFile][SortedKeys.index(Tokens[i])]+=1\n",
    "            \n",
    "                TermIdfMatrix[IndexOfFile][SortedKeys.index(Tokens[i])]=1\n",
    "        \n",
    "            MatrixForTrainDataset[IndexOfFile][len(MatrixForTrainDataset[IndexOfFile])-1]=Folder\n",
    "        \n",
    "            TermIdfMatrix[IndexOfFile][len(MatrixForTrainDataset[IndexOfFile])-1]=Folder\n",
    "        \n",
    "            IndexOfFile+=1\n",
    "    \n",
    "    \n",
    "    for column in range(0,len(TermIdfMatrix[0])-1):\n",
    "        \n",
    "        NoOfDocumentForTerm=0\n",
    "    \n",
    "        for row in range(0,len(TermIdfMatrix)):\n",
    "            \n",
    "            NoOfDocumentForTerm+=TermIdfMatrix[row][column]\n",
    "    \n",
    "    \n",
    "        for row in range(0,len(TermIdfMatrix)):\n",
    "            \n",
    "            if MatrixForTrainDataset[row][column]!=0:\n",
    "                \n",
    "                MatrixForTrainDataset[row][column]*=(math.log2(TotalTrainDocuments/NoOfDocumentForTerm))\n",
    "    \n",
    "    \n",
    "    with open('traindata.p', 'wb') as fp:\n",
    "        pickle.dump(MatrixForTrainDataset,fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    with open('IdfScores.p', 'wb') as fp:\n",
    "        pickle.dump(TermIdfMatrix,fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "    return TermIdfMatrix,MatrixForTrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "File Found\n",
      "Printing Train Data .................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$1</th>\n",
       "      <th>$125000</th>\n",
       "      <th>$20m</th>\n",
       "      <th>$25m</th>\n",
       "      <th>$30000</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>&amp;#1637m</th>\n",
       "      <th>&amp;#1638m</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>...</th>\n",
       "      <th>â£6</th>\n",
       "      <th>â£600000</th>\n",
       "      <th>â£62m</th>\n",
       "      <th>â£65m</th>\n",
       "      <th>â£6m</th>\n",
       "      <th>â£70m</th>\n",
       "      <th>â£7m</th>\n",
       "      <th>â£7million</th>\n",
       "      <th>â£8m</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.474862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.474862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.949723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 8629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      $1  $125000  $20m  $25m  $30000    &  &#1637m  &#1638m         0   00  \\\n",
       "0    0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  2.474862  0.0   \n",
       "1    0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "2    0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "3    0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "4    0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "..   ...      ...   ...   ...     ...  ...      ...      ...       ...  ...   \n",
       "512  0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "513  0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  2.474862  0.0   \n",
       "514  0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  4.949723  0.0   \n",
       "515  0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "516  0.0      0.0   0.0   0.0     0.0  0.0      0.0      0.0  0.000000  0.0   \n",
       "\n",
       "     ...  â£6  â£600000  â£62m  â£65m  â£6m  â£70m  â£7m  â£7million  â£8m  \\\n",
       "0    ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "1    ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "2    ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "3    ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "4    ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "..   ...  ...       ...    ...    ...   ...    ...   ...         ...   ...   \n",
       "512  ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "513  ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "514  ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "515  ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "516  ...  0.0       0.0    0.0    0.0   0.0    0.0   0.0         0.0   0.0   \n",
       "\n",
       "         Class  \n",
       "0    athletics  \n",
       "1    athletics  \n",
       "2    athletics  \n",
       "3    athletics  \n",
       "4    athletics  \n",
       "..         ...  \n",
       "512     tennis  \n",
       "513     tennis  \n",
       "514     tennis  \n",
       "515     tennis  \n",
       "516     tennis  \n",
       "\n",
       "[517 rows x 8629 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"*\"*124)\n",
    "    \n",
    "    File = open(\"IdfScores.p\",\"rb\")\n",
    "    TermIdfMatrix=pickle.load(File)\n",
    "    \n",
    "    File = open(\"traindata.p\",\"rb\")\n",
    "    MatrixForTrainDataset=pickle.load(File)\n",
    "    \n",
    "    print(\"File Found\")\n",
    "    \n",
    "    print(\"Printing Train Data .................\")\n",
    "    \n",
    "    columns=SortedKeys.copy()\n",
    "    \n",
    "    columns.append(\"Class\")\n",
    "    \n",
    "    File=pd.DataFrame(MatrixForTrainDataset,columns=columns)\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"*\"*124)\n",
    "    \n",
    "except:\n",
    "    \n",
    "    print(\"File Not Found\")\n",
    "    \n",
    "    print(\"Creating Files .................\")\n",
    "    \n",
    "    TermIdfMatrix,MatrixForTrainDataset=GeneratingTrainCsvFile(Dictionary)\n",
    "    \n",
    "    columns=SortedKeys.copy()\n",
    "    \n",
    "    columns.append(\"Class\")\n",
    "    \n",
    "    File=pd.DataFrame(MatrixForTrainDataset,columns=columns)\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"Files Created !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Test Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Total Test Folders          :  5\n",
      "Total Test Documents        :  220\n",
      "Documents In Athletics Class :  30\n",
      "Documents In Cricket Class   :  37\n",
      "Documents In Football Class  :  79\n",
      "Documents In Rugby Class     :  44\n",
      "Documents In Tennis Class    :  30\n",
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*124)\n",
    "print(\"Total Test Folders          : \",GetTotalFolder('Test/'))\n",
    "print(\"Total Test Documents        : \",GetTotalDocuments('Test/'))\n",
    "print(\"Documents In Athletics Class : \",GetTotalFilesInClass('athletics','Test/'))\n",
    "print(\"Documents In Cricket Class   : \",GetTotalFilesInClass('cricket','Test/'))\n",
    "print(\"Documents In Football Class  : \",GetTotalFilesInClass('football','Test/'))\n",
    "print(\"Documents In Rugby Class     : \",GetTotalFilesInClass('rugby','Test/'))\n",
    "print(\"Documents In Tennis Class    : \",GetTotalFilesInClass('tennis','Test/'))\n",
    "print(\"*\"*124)\n",
    "TotalTestDocuments=GetTotalDocuments('Test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratingTestCsvFile(Dictionary,TermIdfMatrix):\n",
    "    \n",
    "    SortedKeys=sorted(Dictionary)\n",
    "    \n",
    "    MatrixForTestDataset=[[0 for i in range(0,len(SortedKeys)+1)]for j in range(0,TotalTestDocuments)]\n",
    "    \n",
    "    IndexOfFile=0\n",
    "\n",
    "    Folders=next(os.walk('Test/'))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk('Test/'+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "        \n",
    "            File=open(\"Test/\"+Folder+'/'+FileName)\n",
    "        \n",
    "            Speech=File.readlines()\n",
    "        \n",
    "            # Filtering Data\n",
    "        \n",
    "            StopWordList=GeneratingStopWordsList(StopWords)\n",
    "        \n",
    "            Tokens=GenerateTokensBySpace(Speech)\n",
    "        \n",
    "            Tokens=RemovingContractions(Tokens)\n",
    "        \n",
    "            Tokens=RemovingDots(Tokens)\n",
    "        \n",
    "            Tokens=LOWERCASECONVERTOR(Tokens)\n",
    "        \n",
    "            Tokens=RemovingBraces(Tokens)\n",
    "        \n",
    "            Tokens=RemovingHypens(Tokens)\n",
    "            \n",
    "            Tokens=FinalFilter(Tokens)\n",
    "        \n",
    "            Tokens=RemovingStopWords(Tokens,StopWordList)\n",
    "        \n",
    "            Tokens=PorterStemming(Tokens)\n",
    "        \n",
    "        \n",
    "            for i in range(0,len(Tokens)):\n",
    "                try:\n",
    "                    MatrixForTestDataset[IndexOfFile][SortedKeys.index(Tokens[i])]+=1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        \n",
    "            MatrixForTestDataset[IndexOfFile][len(MatrixForTestDataset[IndexOfFile])-1]=Folder\n",
    "        \n",
    "            IndexOfFile+=1\n",
    "      \n",
    "    \n",
    "    for column in range(0,len(TermIdfMatrix[0])-1):\n",
    "    \n",
    "        NoOfDocumentForTerm=0\n",
    "    \n",
    "        for row in range(0,len(TermIdfMatrix)):\n",
    "        \n",
    "            NoOfDocumentForTerm+=TermIdfMatrix[row][column]\n",
    "    \n",
    "    \n",
    "        for row in range(0,len(MatrixForTestDataset)):\n",
    "        \n",
    "            if MatrixForTestDataset[row][column]!=0:\n",
    "            \n",
    "                MatrixForTestDataset[row][column]*=(math.log2(TotalTrainDocuments/NoOfDocumentForTerm))\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open('testdata.p', 'wb') as fp:\n",
    "        \n",
    "        pickle.dump(MatrixForTestDataset,fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return MatrixForTestDataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "File Found\n",
      "Printing Test Data .................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$1</th>\n",
       "      <th>$125000</th>\n",
       "      <th>$20m</th>\n",
       "      <th>$25m</th>\n",
       "      <th>$30000</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>&amp;#1637m</th>\n",
       "      <th>&amp;#1638m</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>...</th>\n",
       "      <th>â£6</th>\n",
       "      <th>â£600000</th>\n",
       "      <th>â£62m</th>\n",
       "      <th>â£65m</th>\n",
       "      <th>â£6m</th>\n",
       "      <th>â£70m</th>\n",
       "      <th>â£7m</th>\n",
       "      <th>â£7million</th>\n",
       "      <th>â£8m</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.474862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.474862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 8629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     $1  $125000  $20m  $25m  $30000    &  &#1637m  &#1638m         0  00  \\\n",
       "0     0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "1     0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "2     0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "3     0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "4     0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "..   ..      ...   ...   ...     ...  ...      ...      ...       ...  ..   \n",
       "215   0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "216   0        0     0   0.0       0  0.0        0        0  2.474862   0   \n",
       "217   0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "218   0        0     0   0.0       0  0.0        0        0  0.000000   0   \n",
       "219   0        0     0   0.0       0  0.0        0        0  2.474862   0   \n",
       "\n",
       "     ...  â£6  â£600000  â£62m  â£65m  â£6m  â£70m  â£7m  â£7million  â£8m  \\\n",
       "0    ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "1    ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "2    ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "3    ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "4    ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "..   ...  ...       ...    ...    ...   ...    ...   ...         ...   ...   \n",
       "215  ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "216  ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "217  ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "218  ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "219  ...  0.0         0      0      0   0.0      0     0           0   0.0   \n",
       "\n",
       "         Class  \n",
       "0    athletics  \n",
       "1    athletics  \n",
       "2    athletics  \n",
       "3    athletics  \n",
       "4    athletics  \n",
       "..         ...  \n",
       "215     tennis  \n",
       "216     tennis  \n",
       "217     tennis  \n",
       "218     tennis  \n",
       "219     tennis  \n",
       "\n",
       "[220 rows x 8629 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"*\"*124)\n",
    "    \n",
    "    File = open(\"testdata.p\",\"rb\")\n",
    "    \n",
    "    MatrixForTestDataset=pickle.load(File)\n",
    "    \n",
    "    print(\"File Found\")\n",
    "    \n",
    "    print(\"Printing Test Data .................\")\n",
    "    \n",
    "    columns=SortedKeys.copy()\n",
    "    \n",
    "    columns.append(\"Class\")\n",
    "    \n",
    "    File=pd.DataFrame(MatrixForTestDataset,columns=columns)\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"*\"*124)\n",
    "    \n",
    "except:\n",
    "    \n",
    "    print(\"File Not Found\")\n",
    "    \n",
    "    print(\"Creating Files .................\")\n",
    "    \n",
    "    MatrixForTestDataset=GeneratingTestCsvFile(Dictionary,TermIdfMatrix)\n",
    "    \n",
    "    columns=SortedKeys.copy()\n",
    "    \n",
    "    columns.append(\"Class\")\n",
    "    \n",
    "    File=pd.DataFrame(MatrixForTestDataset,columns=columns)\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"Files Created !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratingTestOutputCsvFile():\n",
    "    \n",
    "    print(\"*\"*124)\n",
    "    \n",
    "    print(\"Generating Matrix To Be Saved in File\")\n",
    "    \n",
    "    TrainDocIndex=0\n",
    "\n",
    "    Output=[]\n",
    "\n",
    "    Folders=next(os.walk('Test/'))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk('Test/'+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "            \n",
    "            l=[]\n",
    "            \n",
    "            l.append(\"DOCUMENT \"+str(TrainDocIndex))\n",
    "            \n",
    "            l.append(Folder)\n",
    "            \n",
    "            Output.append(l)\n",
    "        \n",
    "            TrainDocIndex+=1\n",
    "        \n",
    "    \n",
    "    Matrix=np.array(Output)\n",
    "    \n",
    "    print(\"Matrix Generated\")\n",
    "    \n",
    "    columns=['Actual Output']\n",
    "    \n",
    "    columns.insert(0,' DOCUMENT INDEX ')\n",
    "    \n",
    "    print(\"Creating File................\")\n",
    "    \n",
    "    File=pd.DataFrame(Matrix,columns=columns)\n",
    "    \n",
    "    File.to_csv(\"Test output.csv\",index=False)\n",
    "    \n",
    "    print(\"File Created \")\n",
    "    \n",
    "    print(\"Printing Test Data Set \")\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"*\"*124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Generating Matrix To Be Saved in File\n",
      "Matrix Generated\n",
      "Creating File................\n",
      "File Created \n",
      "Printing Test Data Set \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCUMENT INDEX</th>\n",
       "      <th>Actual Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOCUMENT 0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOCUMENT 1</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOCUMENT 2</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOCUMENT 3</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCUMENT 4</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>DOCUMENT 215</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>DOCUMENT 216</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>DOCUMENT 217</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>DOCUMENT 218</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>DOCUMENT 219</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DOCUMENT INDEX  Actual Output\n",
       "0         DOCUMENT 0     athletics\n",
       "1         DOCUMENT 1     athletics\n",
       "2         DOCUMENT 2     athletics\n",
       "3         DOCUMENT 3     athletics\n",
       "4         DOCUMENT 4     athletics\n",
       "..               ...           ...\n",
       "215     DOCUMENT 215        tennis\n",
       "216     DOCUMENT 216        tennis\n",
       "217     DOCUMENT 217        tennis\n",
       "218     DOCUMENT 218        tennis\n",
       "219     DOCUMENT 219        tennis\n",
       "\n",
       "[220 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "GeneratingTestOutputCsvFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadFiles():\n",
    "    \n",
    "    output=pd.read_csv('Test output.csv')\n",
    "    \n",
    "    with open('traindata.p', 'rb') as fp:\n",
    "        MatrixForTrainDataset=pickle.load(fp)\n",
    "    with open('testdata.p', 'rb') as fp:\n",
    "        MatrixForTestDataset=pickle.load(fp)\n",
    "    \n",
    "    \n",
    "#     return train,test,output,MatrixForTestDataset,MatrixForTrainDataset\n",
    "\n",
    "    return output,MatrixForTestDataset,MatrixForTrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test,output,MatrixForTestDataset,MatrixForTrainDataset=LoadFiles()\n",
    "output,MatrixForTestDataset,MatrixForTrainDataset=LoadFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakingPredictionFile(MatrixForTestDataset,MatrixForTrainDataset):\n",
    "    \n",
    "    index=0\n",
    "    PredictCorrect=0\n",
    "    PredictWrong=0\n",
    "    ActualClass=\"athletics\"\n",
    "    TotalClassDocuments=0\n",
    "\n",
    "    PredictedResult=[]\n",
    "\n",
    "    for Test in range(0,len(MatrixForTestDataset)):\n",
    "    \n",
    "    \n",
    "        Result={}\n",
    "    \n",
    "    \n",
    "        ActualClass=MatrixForTestDataset[Test][len(MatrixForTestDataset[0])-1]\n",
    "    \n",
    "    \n",
    "        Distance1=sys.maxsize\n",
    "        Distance2=sys.maxsize\n",
    "        Distance3=sys.maxsize\n",
    "    \n",
    "        Class1=\"\"\n",
    "        Class2=\"\"\n",
    "        Class3=\"\"\n",
    "    \n",
    "        DocTest=MatrixForTestDataset[Test][1:len(MatrixForTestDataset[Test])-1]\n",
    "    \n",
    "        for Train in range(0,len(MatrixForTrainDataset)):\n",
    "        \n",
    "        \n",
    "            ClassTrain=MatrixForTrainDataset[Train][len(MatrixForTrainDataset[0])-1]\n",
    "        \n",
    "            DocTrain=MatrixForTrainDataset[Train][1:len(MatrixForTrainDataset[Train])-1]\n",
    "        \n",
    "            distance = math.sqrt(sum([(float(a) - float(b)) ** 2 for a, b in zip(DocTest,DocTrain)]))\n",
    "        \n",
    "#         Result.setdefault(distance,ClassTrain)\n",
    "    \n",
    "    \n",
    "            if distance<Distance1 and distance<Distance2 and distance<Distance3:\n",
    "            \n",
    "                Distance1=distance\n",
    "                Class1=ClassTrain\n",
    "            \n",
    "            elif distance<Distance2 and distance<Distance3:\n",
    "            \n",
    "                Distance2=distance\n",
    "                Class2=ClassTrain\n",
    "            \n",
    "            elif distance<Distance3:\n",
    "            \n",
    "                Distance3=distance\n",
    "                Class3=ClassTrain\n",
    "      \n",
    "    \n",
    "#     print([b for a, b in sorted(Result.items())][0:3])\n",
    "    \n",
    "        Result.setdefault(Distance3,Class3)\n",
    "        Result.setdefault(Distance2,Class2)\n",
    "        Result.setdefault(Distance1,Class1)\n",
    "    \n",
    "        index=0\n",
    "    \n",
    "        DistanceSortedResult={}\n",
    "    \n",
    "    \n",
    "        for i in sorted(Result):\n",
    "        \n",
    "            if Result[i] in DistanceSortedResult.keys():\n",
    "            \n",
    "                j=DistanceSortedResult[Result[i]]\n",
    "                j+=1\n",
    "                DistanceSortedResult[Result[i]]=j\n",
    "            \n",
    "            else:\n",
    "                DistanceSortedResult.setdefault(Result[i],1)\n",
    "            index+=1\n",
    "            if index==3:\n",
    "                break\n",
    "    \n",
    "        PredictedClass=\"\"\n",
    "        for key,value in DistanceSortedResult.items():\n",
    "            PredictedClass=key\n",
    "            break\n",
    "\n",
    "        PredictedResult.append(PredictedClass)\n",
    "    \n",
    "        if PredictedClass==ActualClass:\n",
    "            PredictCorrect+=1\n",
    "        else:\n",
    "            PredictWrong+=1\n",
    "        \n",
    "        TotalClassDocuments+=1\n",
    "    \n",
    "    Prediction=[]\n",
    "    docno=0\n",
    "    for i in PredictedResult:\n",
    "        l=[]\n",
    "        doc=\"Document \"+str(docno)\n",
    "        l.append(doc)\n",
    "        l.append(i)\n",
    "        Prediction.append(l)\n",
    "        docno+=1\n",
    "    pd.DataFrame(Prediction,columns=[\"Document Index\",\"Predicted Ouptut\"]).to_csv(\"Predicted Output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Prediction File Found\n",
      "Printing Output Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Index</th>\n",
       "      <th>Predicted Ouptut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Document 0</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Document 1</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Document 2</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Document 3</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Document 4</td>\n",
       "      <td>athletics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Document 215</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Document 216</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Document 217</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Document 218</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Document 219</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document Index Predicted Ouptut\n",
       "0       Document 0        athletics\n",
       "1       Document 1        athletics\n",
       "2       Document 2        athletics\n",
       "3       Document 3        athletics\n",
       "4       Document 4        athletics\n",
       "..             ...              ...\n",
       "215   Document 215           tennis\n",
       "216   Document 216           tennis\n",
       "217   Document 217         football\n",
       "218   Document 218         football\n",
       "219   Document 219           tennis\n",
       "\n",
       "[220 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"*\"*124)\n",
    "    \n",
    "    print(\"Prediction File Found\")\n",
    "    \n",
    "    displayTrainDataset=pd.read_csv(\"Predicted Output.csv\")\n",
    "    \n",
    "    print(\"Printing Output Data\")\n",
    "    \n",
    "    display(displayTrainDataset)\n",
    "    \n",
    "    print(\"*\"*124)\n",
    "    \n",
    "except:\n",
    "    print(\"*\"*124)\n",
    "    print(\"File Not Found\")\n",
    "    print(\"Creating Files .................\")\n",
    "    MakingPredictionFile(MatrixForTestDataset,MatrixForTrainDataset)\n",
    "    print(\"Files Created !\")\n",
    "    \n",
    "    displayTrainDataset=pd.read_csv(\"Predicted Output.csv\")\n",
    "    \n",
    "    print(\"Printing Output Data\")\n",
    "    \n",
    "    display(displayTrainDataset)\n",
    "    \n",
    "    print(\"*\"*124)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   Athletics\n",
      "Total Test Documents:    30\n",
      "Predicted right:    28\n",
      "Predicted wrong:    2\n",
      "Athletics  Class Accuracy:    93.33333333333333\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   Cricket\n",
      "Total Test Documents:    37\n",
      "Predicted right:    30\n",
      "Predicted wrong:    7\n",
      "Cricket  Class Accuracy:    81.08108108108108\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   Football\n",
      "Total Test Documents:    79\n",
      "Predicted right:    73\n",
      "Predicted wrong:    6\n",
      "Football  Class Accuracy:    92.40506329113924\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   Rugby\n",
      "Total Test Documents:    44\n",
      "Predicted right:    39\n",
      "Predicted wrong:    5\n",
      "Rugby  Class Accuracy:    88.63636363636364\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   Tennis\n",
      "Total Test Documents:    30\n",
      "Predicted right:    23\n",
      "Predicted wrong:    7\n",
      "Tennis  Class Accuracy:    76.66666666666667\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Total Accuracy :           87.72727272727273\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "TestOutput=pd.read_csv('Test output.csv')\n",
    "PredictedOutput=pd.read_csv(\"Predicted Output.csv\")\n",
    "\n",
    "index=0\n",
    "PredictCorrect=0\n",
    "PredictWrong=0\n",
    "ActualClass=\"athletics\"\n",
    "TotalClassDocuments=0\n",
    "TotalPredictedCorrect=0\n",
    "\n",
    "print(\">\"*123)\n",
    "for i,y in zip(TestOutput['Actual Output'],PredictedOutput['Predicted Ouptut']):\n",
    "    \n",
    "    PreviousClass=ActualClass\n",
    "    \n",
    "    ActualClass=i\n",
    "    \n",
    "    AfterClass=ActualClass\n",
    "    \n",
    "    if PreviousClass!=AfterClass:\n",
    "        \n",
    "        print(\"-\"*123)\n",
    "        print(\" \"*50,PreviousClass.capitalize())\n",
    "        print(\"Total Test Documents:   \",TotalClassDocuments)\n",
    "        print(\"Predicted right:   \",PredictCorrect)\n",
    "        print(\"Predicted wrong:   \",PredictWrong)\n",
    "        print(PreviousClass.capitalize(),\" Class Accuracy:   \",(PredictCorrect/TotalClassDocuments)*100)\n",
    "        print(\"-\"*123)\n",
    "        PredictCorrect=0\n",
    "        PredictWrong=0\n",
    "        TotalClassDocuments=0\n",
    "    \n",
    "    if i==y:\n",
    "        TotalPredictedCorrect+=1\n",
    "        PredictCorrect+=1\n",
    "    else:\n",
    "        PredictWrong+=1\n",
    "        \n",
    "    TotalClassDocuments+=1\n",
    "\n",
    "print(\"-\"*123)\n",
    "print(\" \"*50,PreviousClass.capitalize())\n",
    "print(\"Total Test Documents:   \",TotalClassDocuments)\n",
    "print(\"Predicted right:   \",PredictCorrect)\n",
    "print(\"Predicted wrong:   \",PredictWrong)\n",
    "print(PreviousClass.capitalize(),\" Class Accuracy:   \",(PredictCorrect/TotalClassDocuments)*100)\n",
    "print(\"-\"*123)\n",
    "print(\"Total Accuracy :          \",(TotalPredictedCorrect/len(MatrixForTestDataset))*100)\n",
    "print(\">\"*123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassDistributionOfTerms():\n",
    "    \n",
    "    Dictionary={}\n",
    "    \n",
    "    Folders=next(os.walk('bbcsport/'))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk('bbcsport/'+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "        \n",
    "            File=open(\"bbcsport/\"+Folder+'/'+FileName)\n",
    "        \n",
    "            Speech=File.readlines()\n",
    "        \n",
    "            # Filtering Data\n",
    "        \n",
    "            StopWordList=GeneratingStopWordsList(StopWords)\n",
    "        \n",
    "            Tokens=GenerateTokensBySpace(Speech)\n",
    "        \n",
    "            Tokens=RemovingContractions(Tokens)\n",
    "        \n",
    "            Tokens=RemovingDots(Tokens)\n",
    "        \n",
    "            Tokens=LOWERCASECONVERTOR(Tokens)\n",
    "        \n",
    "            Tokens=RemovingBraces(Tokens)\n",
    "        \n",
    "            Tokens=RemovingHypens(Tokens)\n",
    "            \n",
    "            Tokens=FinalFilter(Tokens)\n",
    "        \n",
    "            Tokens=RemovingStopWords(Tokens,StopWordList)\n",
    "        \n",
    "            Tokens=PorterStemming(Tokens)\n",
    "        \n",
    "        \n",
    "            for i in range(0,len(Tokens)):\n",
    "                \n",
    "                if Tokens[i] not in Dictionary:\n",
    "                    \n",
    "                    Dictionary.setdefault(Tokens[i],{})\n",
    "                    \n",
    "                    Dictionary[Tokens[i]].setdefault(Folder,1)\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    if Folder in Dictionary[Tokens[i]]:\n",
    "                        \n",
    "                        Quantity = Dictionary[Tokens[i]][Folder]\n",
    "                        \n",
    "                        Quantity+=1\n",
    "                        \n",
    "                        Dictionary[Tokens[i]][Folder]=Quantity\n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        Dictionary[Tokens[i]].setdefault(Folder,1)\n",
    "    \n",
    "    return Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTotalDatasetFile(FilterPercentage):\n",
    "    \n",
    "    ClassDistribution=ClassDistributionOfTerms()\n",
    "    \n",
    "    QtyTerms=0\n",
    "    \n",
    "    NewDictionary={}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for Term in ClassDistribution:    \n",
    "        \n",
    "        for Class in ClassDistribution[Term]:\n",
    "                \n",
    "            if ClassDistribution[Term][Class]>=3:\n",
    "                \n",
    "                QtyTerms+=1\n",
    "        \n",
    "                NewDictionary.setdefault(Term)\n",
    "        \n",
    "    SortedKeys=sorted(NewDictionary)\n",
    "    \n",
    "    \n",
    "    Folders=next(os.walk('bbcsport/'))[1]\n",
    "    TotalDocuments=len(next(os.walk('bbcsport/'+Folders[0]))[2])\n",
    "    TotalDocuments+=len(next(os.walk('bbcsport/'+Folders[1]))[2])\n",
    "    TotalDocuments+=len(next(os.walk('bbcsport/'+Folders[2]))[2])\n",
    "    TotalDocuments+=len(next(os.walk('bbcsport/'+Folders[3]))[2])\n",
    "    TotalDocuments+=len(next(os.walk('bbcsport/'+Folders[4]))[2])\n",
    "\n",
    "    \n",
    "    \n",
    "    MatrixForTrainDataset=[[0 for i in range(0,len(SortedKeys)+1)]for j in range(0,TotalDocuments)]\n",
    "\n",
    "    TermIdfMatrix=[[0 for i in range(0,len(SortedKeys)+1)]for j in range(0,TotalDocuments)]\n",
    "    \n",
    "    IndexOfFile=0\n",
    "\n",
    "    Folders=next(os.walk('bbcsport/'))[1]\n",
    "\n",
    "    for Folder in Folders:\n",
    "    \n",
    "        Files=next(os.walk('bbcsport/'+Folder))[2]\n",
    "    \n",
    "        for FileName in Files:\n",
    "        \n",
    "            File=open(\"bbcsport/\"+Folder+'/'+FileName)\n",
    "        \n",
    "            Speech=File.readlines()\n",
    "        \n",
    "            # Filtering Data\n",
    "        \n",
    "            StopWordList=GeneratingStopWordsList(StopWords)\n",
    "        \n",
    "            Tokens=GenerateTokensBySpace(Speech)\n",
    "        \n",
    "            Tokens=RemovingContractions(Tokens)\n",
    "        \n",
    "            Tokens=RemovingDots(Tokens)\n",
    "        \n",
    "            Tokens=LOWERCASECONVERTOR(Tokens)\n",
    "        \n",
    "            Tokens=RemovingBraces(Tokens)\n",
    "        \n",
    "            Tokens=RemovingHypens(Tokens)\n",
    "            \n",
    "            Tokens=FinalFilter(Tokens)\n",
    "        \n",
    "            Tokens=RemovingStopWords(Tokens,StopWordList)\n",
    "        \n",
    "            Tokens=PorterStemming(Tokens)\n",
    "        \n",
    "        \n",
    "            for i in range(0,len(Tokens)):\n",
    "                \n",
    "                try:\n",
    "            \n",
    "                    MatrixForTrainDataset[IndexOfFile][SortedKeys.index(Tokens[i])]+=1\n",
    "            \n",
    "                    TermIdfMatrix[IndexOfFile][SortedKeys.index(Tokens[i])]=1\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "         \n",
    "\n",
    "        \n",
    "            MatrixForTrainDataset[IndexOfFile][len(MatrixForTrainDataset[IndexOfFile])-1]=Folder\n",
    "        \n",
    "        \n",
    "            TermIdfMatrix[IndexOfFile][len(MatrixForTrainDataset[IndexOfFile])-1]=Folder\n",
    "        \n",
    "            IndexOfFile+=1\n",
    "    \n",
    "    \n",
    "    for column in range(0,len(TermIdfMatrix[0])-1):\n",
    "        \n",
    "        NoOfDocumentForTerm=0\n",
    "    \n",
    "        for row in range(0,len(TermIdfMatrix)):\n",
    "            \n",
    "            NoOfDocumentForTerm+=TermIdfMatrix[row][column]\n",
    "            \n",
    "    \n",
    "        for row in range(0,len(TermIdfMatrix)):\n",
    "            \n",
    "            if MatrixForTrainDataset[row][column]!=0:\n",
    "                \n",
    "                MatrixForTrainDataset[row][column]*=(math.log2(TotalDocuments/NoOfDocumentForTerm))\n",
    "    \n",
    "    \n",
    "    with open('Kmeansdataset.p', 'wb') as fp:\n",
    "        pickle.dump(MatrixForTrainDataset,fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return MatrixForTrainDataset,SortedKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Total data Set File Found\n",
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"*\"*124)\n",
    "    File = open(\"Kmeansdataset.p\",\"rb\")\n",
    "    MatrixForTrainDataset = pickle.load(File)\n",
    "    print(\"Total data Set File Found\")\n",
    "    print(\"*\"*124)\n",
    "except:\n",
    "    \n",
    "    print(\"File Not Found\")\n",
    "    \n",
    "    print(\"Creating Files .................\")\n",
    "    \n",
    "    MatrixForTrainDataset,Dictionary = GenerateTotalDatasetFile()\n",
    "    \n",
    "    SortedKeys=sorted(Dictionary)\n",
    "    \n",
    "    print(\"Printing Train Data .................\")\n",
    "    \n",
    "    columns=SortedKeys.copy()\n",
    "    \n",
    "    columns.append(\"Class\")\n",
    "    \n",
    "    File=pd.DataFrame(MatrixForTrainDataset,columns=columns)\n",
    "    \n",
    "    display(File)\n",
    "    \n",
    "    print(\"Files Created !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetDocuments(D1,D2,D3,D4,D5):\n",
    "    \n",
    "    NewMatrixForTrainDataset=np.delete(MatrixForTrainDataset,(D1,D2,D3,D4,D5),axis=0)\n",
    "    \n",
    "    D1=MatrixForTrainDataset[D1]\n",
    "    D2=MatrixForTrainDataset[D2]\n",
    "    D3=MatrixForTrainDataset[D3]\n",
    "    D4=MatrixForTrainDataset[D4]\n",
    "    D5=MatrixForTrainDataset[D5]\n",
    "    \n",
    "    return MatrixForTrainDataset,NewMatrixForTrainDataset,D1,D2,D3,D4,D5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DocumentCluster(D1,D2,D3,D4,D5):\n",
    "    \n",
    "    DocumentCluster={}\n",
    "    \n",
    "    DocumentCluster.setdefault(0,[])\n",
    "    DocumentCluster.setdefault(1,[])\n",
    "    DocumentCluster.setdefault(2,[])\n",
    "    DocumentCluster.setdefault(3,[])\n",
    "    DocumentCluster.setdefault(4,[])\n",
    "    \n",
    "    \n",
    "    MatrixForTrainDataset,NewMatrixForTrainDataset,D1,D2,D3,D4,D5=SetDocuments(D1,D2,D3,D4,D5)\n",
    "    \n",
    "    RandomFiveDocuments=[D1,D2,D3,D4,D5]\n",
    "    \n",
    "    print(\"Calculating Distance ...............................\")\n",
    "    \n",
    "    for i in range(0,len(NewMatrixForTrainDataset)):\n",
    "    \n",
    "        DocTrain=NewMatrixForTrainDataset[i][0:len(NewMatrixForTrainDataset[0])-1]\n",
    "    \n",
    "        MiniMumDistance={}\n",
    "    \n",
    "        for j in range(0,len(RandomFiveDocuments)):\n",
    "        \n",
    "            DocTest=RandomFiveDocuments[j][0:len(RandomFiveDocuments[0])-1]\n",
    "            \n",
    "#             print(DocTrain)\n",
    "            \n",
    "            DocTestMagnitude=math.sqrt(sum([float(a)**2 for a in DocTest]))\n",
    "            \n",
    "            DocTrainMagnitude=math.sqrt(sum([float(a)**2 for a in DocTrain]))\n",
    "            \n",
    "            Magnitude=DocTestMagnitude*DocTrainMagnitude\n",
    "            \n",
    "            distance=sum([(float(a)*float(b)) for a, b in zip(DocTest,DocTrain)])\n",
    "            \n",
    "            if Magnitude==0:\n",
    "                \n",
    "                distance=0\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                distance=distance/Magnitude\n",
    "        \n",
    "            MiniMumDistance.setdefault(distance,j)\n",
    "    \n",
    "        DocumentCluster[[b for a, b in sorted(MiniMumDistance.items(),reverse=True)][0]].append(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Calculating Mean .................................................\")\n",
    "    \n",
    "    \n",
    "    DocumentClusterMean={}\n",
    "    \n",
    "    DocumentClusterMean.setdefault(0,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "    DocumentClusterMean.setdefault(1,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "    DocumentClusterMean.setdefault(2,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "    DocumentClusterMean.setdefault(3,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "    DocumentClusterMean.setdefault(4,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for Cluster in range(0,len(DocumentCluster)):\n",
    "    \n",
    "        for Doc in DocumentCluster[Cluster]:\n",
    "        \n",
    "            MatrixOne=DocumentClusterMean[Cluster]\n",
    "        \n",
    "            MatrixTwo=MatrixForTrainDataset[Doc][0:len(MatrixForTrainDataset[0])-1]\n",
    "        \n",
    "            DocumentClusterMean[Cluster]=[x+y for x,y in zip(MatrixOne,MatrixTwo)]\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            DocumentClusterMean[Cluster] = [float(x) / float(len(DocumentCluster[Cluster]))  for x in DocumentClusterMean[Cluster] ]\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    DocumentClusterAfterMean={}\n",
    "    \n",
    "    DocumentClusterAfterMean.setdefault(0,[])\n",
    "    \n",
    "    DocumentClusterAfterMean.setdefault(1,[])\n",
    "    \n",
    "    DocumentClusterAfterMean.setdefault(2,[])\n",
    "    \n",
    "    DocumentClusterAfterMean.setdefault(3,[])\n",
    "    \n",
    "    DocumentClusterAfterMean.setdefault(4,[])\n",
    "    \n",
    "    print(\"Calculating Document Cluster After Calculating Mean ................................\")\n",
    "    \n",
    "    for i in range(0,len(MatrixForTrainDataset)):\n",
    "    \n",
    "        DocTrain=MatrixForTrainDataset[i][0:len(MatrixForTrainDataset[0])-1]\n",
    "    \n",
    "        MiniMumDistance={}\n",
    "    \n",
    "        for j in range(0,len(DocumentClusterMean)):\n",
    "        \n",
    "            DocTest=DocumentClusterMean[j]\n",
    "            \n",
    "            DocTestMagnitude=math.sqrt(sum([float(a)**2 for a in DocTest]))\n",
    "            \n",
    "            DocTrainMagnitude=math.sqrt(sum([float(a)**2 for a in DocTrain]))\n",
    "            \n",
    "            Magnitude=DocTestMagnitude*DocTrainMagnitude\n",
    "            \n",
    "            distance=sum([(float(a)*float(b)) for a, b in zip(DocTest,DocTrain)])\n",
    "            \n",
    "            if Magnitude==0:\n",
    "                \n",
    "                distance=0\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                distance=distance/Magnitude\n",
    "        \n",
    "            MiniMumDistance.setdefault(distance,j)\n",
    "    \n",
    "        DocumentClusterAfterMean[[b for a, b in sorted(MiniMumDistance.items(),reverse=True)][0]].append(i)\n",
    "    \n",
    "    \n",
    "    print(\"Converging Cluster...............................\")\n",
    "    \n",
    "    Iterations=0\n",
    "    \n",
    "    while DocumentCluster[0]!=DocumentClusterAfterMean[0] or DocumentCluster[1]!=DocumentClusterAfterMean[1] or DocumentCluster[2]!=DocumentClusterAfterMean[2] or DocumentCluster[3]!=DocumentClusterAfterMean[3] or DocumentCluster[4]!=DocumentClusterAfterMean[4]:\n",
    "        \n",
    "        Iterations+=1\n",
    "        \n",
    "        print(\"Iterations : \",Iterations)\n",
    "    \n",
    "        DocumentCluster=DocumentClusterAfterMean\n",
    "    \n",
    "    \n",
    "        DocumentClusterMean={}\n",
    "        \n",
    "        DocumentClusterMean.setdefault(0,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "\n",
    "        DocumentClusterMean.setdefault(1,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "\n",
    "        DocumentClusterMean.setdefault(2,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "        DocumentClusterMean.setdefault(3,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "        DocumentClusterMean.setdefault(4,[0 for i in range(0,len(MatrixForTrainDataset[0]))])\n",
    "    \n",
    "        for Cluster in range(0,len(DocumentClusterAfterMean)):\n",
    "        \n",
    "            for Doc in DocumentClusterAfterMean[Cluster]:\n",
    "            \n",
    "                MatrixOne=DocumentClusterMean[Cluster]\n",
    "            \n",
    "            \n",
    "#                 print(Doc,len(MatrixForTrainDataset[0])-1)\n",
    "                \n",
    "                MatrixTwo=MatrixForTrainDataset[Doc][0:len(MatrixForTrainDataset[0])-1]\n",
    "            \n",
    "                DocumentClusterMean[Cluster]=[x+y for x,y in zip(MatrixOne,MatrixTwo)]\n",
    "     \n",
    "            try:\n",
    "                DocumentClusterMean[Cluster] = [float(x) / float(len(DocumentClusterAfterMean[Cluster]))  for x in DocumentClusterMean[Cluster] ]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "        DocumentClusterAfterMean={}\n",
    "    \n",
    "        DocumentClusterAfterMean.setdefault(0,[])\n",
    "    \n",
    "        DocumentClusterAfterMean.setdefault(1,[])\n",
    "    \n",
    "        DocumentClusterAfterMean.setdefault(2,[])\n",
    "    \n",
    "        DocumentClusterAfterMean.setdefault(3,[])\n",
    "    \n",
    "        DocumentClusterAfterMean.setdefault(4,[])\n",
    "    \n",
    "    \n",
    "        for i in range(0,len(MatrixForTrainDataset)):\n",
    "    \n",
    "            DocTrain=MatrixForTrainDataset[i][0:len(MatrixForTrainDataset[0])-1]\n",
    "    \n",
    "            MiniMumDistance={}\n",
    "    \n",
    "            for j in range(0,len(DocumentClusterMean)):\n",
    "        \n",
    "                DocTest=DocumentClusterMean[j]\n",
    "                \n",
    "                DocTestMagnitude=math.sqrt(sum([float(a)**2 for a in DocTest]))\n",
    "            \n",
    "                DocTrainMagnitude=math.sqrt(sum([float(a)**2 for a in DocTrain]))\n",
    "            \n",
    "                Magnitude=DocTestMagnitude*DocTrainMagnitude\n",
    "            \n",
    "                distance=sum([(float(a)*float(b)) for a, b in zip(DocTest,DocTrain)])\n",
    "                \n",
    "                if Magnitude==0:\n",
    "                    \n",
    "                    distance=0\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    distance=distance/Magnitude\n",
    "        \n",
    "                MiniMumDistance.setdefault(distance,j)\n",
    "    \n",
    "            DocumentClusterAfterMean[[b for a, b in sorted(MiniMumDistance.items(),reverse=True)][0]].append(i)\n",
    "    \n",
    "    return DocumentCluster,DocumentClusterAfterMean\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************************************\n",
      "Cluster Found\n",
      "****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    print(\"*\"*124)\n",
    "    File = open(\"Cluster.p\",\"rb\")\n",
    "    d = pickle.load(File)\n",
    "    print(\"Cluster Found\")\n",
    "    print(\"*\"*124)\n",
    "except:\n",
    "    \n",
    "    Documents=np.random.randint(low = 1, high = len(MatrixForTrainDataset)-1, size = 5) \n",
    "    d,d2=DocumentCluster(Documents[0],Documents[1],Documents[2],Documents[3],Documents[4])\n",
    "    \n",
    "    with open('Cluster.p', 'wb') as fp:\n",
    "        pickle.dump(d,fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AthleticsClassDocuments=[]\n",
    "TennisClassDocuments=[]\n",
    "RugbyClassDocuments=[]\n",
    "FootballClassDocuments=[]\n",
    "CricketClassDocuments=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(MatrixForTrainDataset)):\n",
    "    if MatrixForTrainDataset[i][len(MatrixForTrainDataset[0])-1]==\"athletics\":\n",
    "        AthleticsClassDocuments.append(i)\n",
    "    if MatrixForTrainDataset[i][len(MatrixForTrainDataset[0])-1]==\"cricket\":\n",
    "        CricketClassDocuments.append(i)\n",
    "    if MatrixForTrainDataset[i][len(MatrixForTrainDataset[0])-1]==\"rugby\":\n",
    "        RugbyClassDocuments.append(i)\n",
    "    if MatrixForTrainDataset[i][len(MatrixForTrainDataset[0])-1]==\"football\":\n",
    "        FootballClassDocuments.append(i)\n",
    "    if MatrixForTrainDataset[i][len(MatrixForTrainDataset[0])-1]==\"tennis\":\n",
    "        TennisClassDocuments.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Cluster : 0\n",
      "Cluster Length :  101\n",
      "Athletics Class Length :  100\n",
      "Football Class Length :  1\n",
      "Rugby Class Length :  0\n",
      "Tennis Class Length :  0\n",
      "Cricket Class Length :  0\n",
      "Cluster :  0  belongs to :  Athletics\n",
      "\n",
      "\n",
      "Cluster : 1\n",
      "Cluster Length :  258\n",
      "Athletics Class Length :  1\n",
      "Football Class Length :  254\n",
      "Rugby Class Length :  0\n",
      "Tennis Class Length :  2\n",
      "Cricket Class Length :  1\n",
      "Cluster :  1  belongs to :  Football\n",
      "\n",
      "\n",
      "Cluster : 2\n",
      "Cluster Length :  98\n",
      "Athletics Class Length :  0\n",
      "Football Class Length :  0\n",
      "Rugby Class Length :  0\n",
      "Tennis Class Length :  98\n",
      "Cricket Class Length :  0\n",
      "Cluster :  2  belongs to :  Tennis\n",
      "\n",
      "\n",
      "Cluster : 3\n",
      "Cluster Length :  160\n",
      "Athletics Class Length :  0\n",
      "Football Class Length :  10\n",
      "Rugby Class Length :  147\n",
      "Tennis Class Length :  0\n",
      "Cricket Class Length :  3\n",
      "Cluster :  3  belongs to :  Rugby\n",
      "\n",
      "\n",
      "Cluster : 4\n",
      "Cluster Length :  120\n",
      "Athletics Class Length :  0\n",
      "Football Class Length :  0\n",
      "Rugby Class Length :  0\n",
      "Tennis Class Length :  0\n",
      "Cricket Class Length :  120\n",
      "Cluster :  4  belongs to :  Cricket\n",
      "\n",
      "\n",
      "Purity Of Cluster is :  97.55766621438264\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "print(\">\"*123)\n",
    "Accuracy=0\n",
    "for i in range(0,5):\n",
    "    R={}\n",
    "    R.setdefault(len(intersection(AthleticsClassDocuments,d[i])),'Athletics')\n",
    "    R.setdefault(len(intersection(FootballClassDocuments,d[i])),'Football')\n",
    "    R.setdefault(len(intersection(TennisClassDocuments,d[i])),'Tennis')\n",
    "    R.setdefault(len(intersection(RugbyClassDocuments,d[i])),'Rugby')\n",
    "    R.setdefault(len(intersection(CricketClassDocuments,d[i])),'Cricket')\n",
    "    print(\"Cluster :\",i)\n",
    "    print(\"Cluster Length : \",len(d[i]))\n",
    "    print(\"Athletics Class Length : \",len(intersection(AthleticsClassDocuments,d[i])))\n",
    "    print(\"Football Class Length : \",len(intersection(FootballClassDocuments,d[i])))\n",
    "    print(\"Rugby Class Length : \",len(intersection(RugbyClassDocuments,d[i])))\n",
    "    print(\"Tennis Class Length : \",len(intersection(TennisClassDocuments,d[i])))\n",
    "    print(\"Cricket Class Length : \",len(intersection(CricketClassDocuments,d[i])))\n",
    "    print(\"Cluster : \",i,\" belongs to : \",[b for a,b in sorted(R.items(),reverse=True)][0])\n",
    "    Accuracy+=[a for a,b in sorted(R.items(),reverse=True)][0]\n",
    "    print(\"\\n\")\n",
    "print(\"Purity Of Cluster is : \",(Accuracy/len(MatrixForTrainDataset))*100)\n",
    "print(\">\"*123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
